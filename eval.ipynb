{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048693ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the tiny MLPerf visual wake word (vww) detection model, this script\n",
    "# downloads the dataset from Silabs and runs both TFLite reference models\n",
    "# (int8-model and float-model) with the 1000 images listed in y_labels.csv\n",
    "# to measure their accuracy\n",
    "#\n",
    "# Usage:\n",
    "#   python3 eval.py\n",
    "#\n",
    "# Alternatively, if you don't want to run this python script locally, you can\n",
    "# run in the cloud by opening the Jupyter Notebook eval.ipynb in your browser\n",
    "# https://colab.research.google.com/github/OpenMachine-ai/mlperf-tools/blob/main/eval.ipynb\n",
    "#\n",
    "# Whenever you change this script, make sure to regenerate the Jupyter Notebook\n",
    "# eval.ipynb as follows:\n",
    "#   pip install jupytext\n",
    "#   jupytext --to notebook eval.py\n",
    "# '# %%' in the code below marks the beginning of a new cell in the notebook\n",
    "\n",
    "import os, csv, PIL\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "# download models, dataset, y_lables.csv, and unzip\n",
    "#-------------------------------------------------------------------------------\n",
    "url = 'https://raw.githubusercontent.com/mlcommons/tiny/master/benchmark/'\n",
    "os.system('curl -O ' + url + 'evaluation/datasets/vww01/y_labels.csv')\n",
    "os.system('curl -O ' + url + 'training/visual_wake_words/trained_models/vww_96_int8.tflite')\n",
    "os.system('curl -O ' + url + 'training/visual_wake_words/trained_models/vww_96_float.tflite')\n",
    "os.system('curl -O https://www.silabs.com/public/files/github/machine_learning/benchmarks/datasets/vw_coco2014_96.tar.gz')\n",
    "os.system('tar -xf vw_coco2014_96.tar.gz')\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "# set up TFLite interpreters for both models int8 (i8) and floating-point (fp)\n",
    "#-------------------------------------------------------------------------------\n",
    "i8_intp = tf.lite.Interpreter(model_path='vww_96_int8.tflite')\n",
    "fp_intp = tf.lite.Interpreter(model_path='vww_96_float.tflite')\n",
    "i8_intp.allocate_tensors()\n",
    "fp_intp.allocate_tensors()\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "# run inference for each file listed in y_labels.csv\n",
    "#-------------------------------------------------------------------------------\n",
    "def inference(intp, img):\n",
    "  \"\"\"run inference for image 'img' using interpreter 'intp' and return the\n",
    "  probability (0.0 ... 1.0) of the image being a person\"\"\"\n",
    "  intp.set_tensor(intp.get_input_details()[0]['index'], img)\n",
    "  intp.invoke()\n",
    "  out = intp.get_tensor(intp.get_output_details()[0]['index'])[0][1]\n",
    "  # for int8-model, convert int8 output (-128..127) to float 0.0 ... 1.0\n",
    "  if np.issubdtype(out.dtype, np.integer):\n",
    "    out = (out + 128) / 256\n",
    "    # TODO: note that the maximum output here is 255/256 = 0.996 = 99.6%, so we\n",
    "    # can never reach exactly 100%. This is a strange thing in TFLite, scaling\n",
    "    # by 1/255 instead of 1/256 would support full range 0% to 100%\n",
    "  return out\n",
    "\n",
    "i8_pass_cnt, fp_pass_cnt, img_cnt = 0, 0, 0\n",
    "with open('y_labels.csv') as f:\n",
    "  for row in csv.reader(f):\n",
    "    # get image 'img' from a file listed in y_labels: row[0] = filename;\n",
    "    # row[2] = '1' or '0' for person/non-person; ignore row[1]\n",
    "    fname = 'COCO_val2014_' + os.path.splitext(row[0])[0] + '.jpg'\n",
    "    dir = 'person/' if row[2] == '1' else 'non_person/'\n",
    "    img = PIL.Image.open('vw_coco2014_96/' + dir + fname)\n",
    "\n",
    "    # convert to numpy array and reshape from (96, 96, 3) to (1, 96, 96, 3)\n",
    "    img = np.asarray(img).reshape(1, 96, 96, 3)  # values are 0..255\n",
    "\n",
    "    # for int8-model, convert from uint8 (0..255) to int8 (-128..127)\n",
    "    i8_img = (img - 128).astype(np.int8)\n",
    "\n",
    "    # for float-model, convert uint8 to float32\n",
    "    fp_img = (img / 256).astype(np.float32)  # TODO, is this correct???\n",
    "\n",
    "    # run inference for both models\n",
    "    i8_out = inference(i8_intp, i8_img)\n",
    "    fp_out = inference(fp_intp, fp_img)\n",
    "\n",
    "    # for debug only: print absolute error of percent-values\n",
    "    #print(int(np.abs(i8_out - fp_out) * 100))\n",
    "\n",
    "    # check if the models were correct and update their pass-counters\n",
    "    img_cnt += 1\n",
    "    if row[2] == '1':\n",
    "      if i8_out >= 0.5: i8_pass_cnt += 1\n",
    "      if fp_out >= 0.5: fp_pass_cnt += 1\n",
    "    else:\n",
    "      if i8_out < 0.5: i8_pass_cnt += 1\n",
    "      if fp_out < 0.5: fp_pass_cnt += 1\n",
    "    # TODO: here we assume probability_of_person >= 0.5 indicates a person\n",
    "    # (as opposed to '> 0.5'). Changing it to '> 0.5' reduces the accuracy by\n",
    "    # 0.3 for the int8-model (no impact for float-model because it almost\n",
    "    # never hits exactly 0.5 float value).  For the int8-model, using >= 0.5\n",
    "    # makes sense because:\n",
    "    #   - there are 256 possible output values for probability_of_person\n",
    "    #   - to be unbiased, map exactly half of these 256 values to 'person',\n",
    "    #     and the other half to 'non-person': values 128..255 -> 'person';\n",
    "    #     values 0..127 -> 'non-person'\n",
    "    #   - so value 128 maps onto 'person', which is exactly 128/256 = 0.5\n",
    "    #     after conversion to float\n",
    "\n",
    "print('float accuracy:', 100 * fp_pass_cnt / img_cnt, '  <--- this should be 80% or higher')\n",
    "print('int8 accuracy :', 100 * i8_pass_cnt / img_cnt, '  <--- this should be 80% or higher')\n",
    "print('image count   :', img_cnt, '  <--- this should be 1000')\n",
    "\n",
    "# TODO: it's strange that running this script in colab produces 85.9%\n",
    "# int8-accuracy, but 86.0% on my MacBook M1. Perhaps the rounding\n",
    "# done by the TFLite interpreter depends on the machine architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d93c2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------\n",
    "# clean up\n",
    "#-------------------------------------------------------------------------------\n",
    "os.system('rm -Rf vw_coco2014_96.tar.gz vw_coco2014_96 y_labels.csv')\n",
    "os.system('rm -Rf vww_96_float.tflite vww_96_int8.tflite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6377fb61",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------\n",
    "references for VWW of MLPerf tiny benchmark\n",
    "-------------------------------------------------------------------------------\n",
    " - benchmark: https://github.com/mlcommons/tiny/tree/master/benchmark\n",
    " - VWW model: https://github.com/mlcommons/tiny/tree/master/benchmark/training/visual_wake_words\n",
    " - Issue #135: https://github.com/mlcommons/tiny/issues/135\n",
    " - Paper 'MLPerf tiny benchmark' https://arxiv.org/pdf/2106.07597.pdf\n",
    " - Paper 'Visual Wake Words Dataset' https://arxiv.org/abs/1906.05721\n",
    " - Source of the data set:\n",
    "   https://github.com/mlcommons/tiny/blob/master/benchmark/training/visual_wake_words/download_and_train_vww.sh\n",
    " - Repo with v1.1 benchmark results:\n",
    "   https://github.com/mlcommons/tiny_results_v1.1/tree/main\n",
    " - Book TinyML https://www.abebooks.com/servlet/SearchResults?kn=TinyML"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
